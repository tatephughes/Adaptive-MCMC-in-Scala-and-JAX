#+TITLE: Adaptive Metropolis in Scala and JAX

:BOILERPLATE:
#+BIBLIOGRAPHY: Bibliography.bib
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [letterpaper]
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage{amsmath,amsfonts,amsthm,amssymb,bm,tikz,tkz-graph}
#+LATEX_HEADER: \usetikzlibrary{arrows}
#+LATEX_HEADER: \usetikzlibrary{bayesnet}
#+LATEX_HEADER: \usetikzlibrary{matrix}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \newtheorem{theorem}{Theorem}[section]
#+LATEX_HEADER: \newtheorem{corollary}[theorem]{Corollary}
#+LATEX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
#+LATEX_HEADER: \newtheorem{definition}[theorem]{Definition}
#+LATEX_HEADER: \newtheorem*{remark}{Remark}
#+LATEX_HEADER: \DeclareMathOperator{\E}{\mathbb E}}
#+LATEX_HEADER: \DeclareMathOperator{\var}{\mathbb V\mathrm{ar}}
#+LATEX_HEADER: \DeclareMathOperator{\cov}{\mathbb C\mathrm{ov}}
#+LATEX_HEADER: \DeclareMathOperator{\cor}{\mathbb C\mathrm{or}}
#+LATEX_HEADER: \newcommand*{\mat}[1]{\bm{#1}}
#+LATEX_HEADER: \renewcommand*{\vec}[1]{\boldsymbol{\mathbf{#1}}}
#+EXPORT_EXCLUDE_TAGS: noexport
:END:

This is my attempt at implementing Adaptive Metropolis in Scala, using the breeze library, and python, using JAX.

This is based on the example from the article "Examples of Adaptive MCMC" by Roberts and Rosenthal.

* Adaptive Metropolis Algorithm

A AMRTH step is defined as follows;
- If $j\leq 2d$, we do a MRTH step with proposal $q(x,\cdot)\sim \mathcal N(x,(0.1)^2I_d/d)$
- If $j>2d$, we use the proposal $q(\vec X_t^* \mid \vec X_0, \dots, X_{t-1}) \sim \mathcal N_d (\vec X_{t-1}, \mat C_j)$, where $C_j$ is the current sampling covariance, updated as below.
  
We can compute the empirical covariance matrix at step $j$ by

\begin{align*}
\vec{\overline{X}}_t &= \frac{t-1}{t} \vec{\overline{X}}_{t-1} + \frac{1}{t} \vec X_t, \\
\mat C_{t+1} &= \frac{t-1}{t} \mat C_t + \frac{s_d}{t}(t\vec{\overline{X}}_{t-1}\vec{\overline{X}}_{t-1}^{\intercal} - (t+1)\vec{\overline{X}}_t\vec{\overline{X}}_t^{\intercal} + \vec X_t\vec X_t^{\intercal} + \epsilon \mat I_d),\quad t\geq t_0.
\end{align*}

The logic I'm using is to carry forward $\vec{\overline x}$ and $C_j$ (as well as the current index, $j$) as part of our 'chain', in order to sample from the proposal.

** Measure of effectiveness

Roberts and Rosenthal also give the following measure of effectiveness;

$$\begin{aligned}
b = d\frac{\sum \lambda_i^{-2}}{(\sum \lambda_i^{-1})^2 },
\end{aligned}$$

where $\lambda_i$ are the eigenvalues of $\Sigma_p^{1/2}\Sigma^{-1/2}$ where $\Sigma_p$ is the empirical variance matrix at the pth iteration.

$b$ should approach 1 as the chain approaches the stationary distribution. Roughly, it measures the difference between the empirical and true variance matrices.

* Example Target

We target the distribution $\pi(\cdot)\sim \mathcal N(0,\Sigma)$, where $\Sigma$ is a matrix sampled from a 'standard' inverse Wishart distribution, i.e., $\Sigma=MM^{\intercal}$, where $M\in\mathbb R^{n \times n}$ is a matrix with random $\mathcal N[0,1]$ entries. In Scala, this can be found as below;

#+begin_src scala
import AdaptiveMetropolis._

// dimension of the state space
val d = 10

// create a chaotic variance to target
val data = Gaussian(0,1).sample(d*d).toArray.grouped(d).toArray
val M = DenseMatrix(data: _*)
val sigma = solve(M.t * M)
#+end_src

Note that Breeze's ~DenseMatrix~ and ~DenseVector~ are actually mutable in Scala, so we need to be careful not to mutate anything.

* Scala implementation

My Scala implementation of this is found in ~Main.scala~ (it needs cleanup though). It is built around an object ~Adaptive Metropolis~, with three methods:

- ~AM_step~, which takes the current state as well as the QR decomposition of the true variance, and outputs the next state of the chain.
- ~AM_iterator~, which iterates ~AM_step~ in order to create an infinite lazy list of samples.
- ~plotter~, which plots the 1st componant of the sample, and saves it to a file.
  
The ~run~ function then tests this, using ~d=10~, ~n=100000~, ~burnin=100000~ and ~thinrate=10~. This function, once it finishes, prints out the true variance of $x_1$, the empirical estimate of it from the sample, the $b$ value, and the time the computation took. A trace plot of $x_1$ is also saved to ~Figures/adaptive_trace_scala.png~.

* JAX implementation

As you might imagine, the JAX implentation is very similar, even if it is a bit more fragmented. The ~AM_step~ function is split into twofunctions, ~try_accept~, and ~adapt_step~. This is mainly due to the way JAX handles ~if else~ statements, making this seem like the convenient way to do it.

In the file ~AM_in_JAX.org~, there is the source code as well as documentation for all the functions, but it is very similar to the scala version.

* Results & Diagnostics

For more detailed results, see the ~diagnostics.org~ file. 

In all implementations, we run with ~d=100~, ~n=100, ~burnin=0~ and ~thinrate=10000~. These settings roughly match the original C code from Roberts and Rosenthal, where 100 iteration results where saved.

For context, the original C code by Roberts and Rosenthal with d=100, n=1000000, took 431.122329 seconds.

The full results of these tests can be made using the ~run.sh~
script found at the root of the project. It also saves the trace plots as ~/Figures/<language>_trace_basetest.png~.

In R:

#+begin_quote
The optimal sampling value of x_1 is 0.02486704566808
The actual sampling value of x_1 is 0.0209341928404325
The initial b value is 1.83282541152906
The final b value is 1.02525674146274
The acceptance rate is 0.103388
The computation took 202.283761262894 seconds

#+end_quote

#+ATTR_ORG: :height 100
[[file:./Figures/r_trace_basetest.png]]

In Scala:

#+begin_quote
The optimal sampling variance of x_1 is 0.02486704566808
The actual sampling variance of x_1 is  0.01937688808349585
The initial b value is 73.4639993467733
The final b value is 1.2516212501470279
The acceptance rate is 0.104118
The computation took 435.751518877 seconds
#+end_quote

#+ATTR_ORG: :height 100
[[file:./Figures/scala_trace_basetest.png]]

And finally in JAX,

#+begin_quote
The optimal sampling variance of x_1 is 0.024867046624422073
The actual sampling variance of x_1 is  0.019067611545324326
The initial b value is 73.5059814453125
The final b value is 1.2530319690704346
The acceptance rate is 0.10468100011348724
The computation took 90.90827989578247 seconds
#+end_quote

#+ATTR_ORG: :height 100
[[file:./Figures/jax_trace_basetest.png]]

or in JAX with mixing

#+begin_quote
JAX output (mixing): 
The optimal sampling variance of x_1 is 0.024867046624422073
The actual sampling variance of x_1 is  0.018218811601400375
The initial b value is 73.5059814453125
The final b value is 1.0261740684509277
The acceptance rate is 0.31248700618743896
The computation took 48.6323938369751 seconds
#+end_quote

We can also plot out the sub optimality factor of each of these;

#+CAPTION: Sub-Optimality Factor accross all 1,000,000 iterations
#+NAME: fig:
[[file:./Figures/plot_mixing_full.png]]

#+CAPTION: Sub-Optimality Factor across the last 500,000 iterations
#+NAME: fig:
[[file:./Figures/plot_mixing_zoomed.png]]

We can see a very clear difference in the performance of the two algorithms; I must say the performance of IC is concerning me a bit, I expected them to perform somewhat similarly.

From here, all versions have a function ~compute_time_graph~ which outputs a csv file containing the time it took to compute over a million iterations for each submatrix of the intputted variance matrix, whcih will be provided from this file. This is then plotted as below using R.

#+begin_src R :session example :results none
#library(ascii)
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)
#+end_src

#+begin_src R :session example :results output
jax_times_laptop_32_IC <- cbind(1:100,read.csv("./data/JAX_32_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "JAX32 (IC)")
names(jax_times_laptop_32_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
jax_times_laptop_32_MD <- cbind(1:100,read.csv("./data/JAX_32_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "JAX32 (MD)")
names(jax_times_laptop_32_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

jax_times_laptop_64_IC <- cbind(1:100,read.csv("./data/JAX_64_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "JAX64 (IC)")
names(jax_times_laptop_64_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
jax_times_laptop_64_MD <- cbind(1:100,read.csv("./data/JAX_64_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "JAX64 (MD)")
names(jax_times_laptop_64_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

r_times_laptop_IC <- cbind(1:100,read.csv("./data/R_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "R (IC)")
names(r_times_laptop_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
r_times_laptop_MD <- cbind(1:100,read.csv("./data/R_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "R (MD)")
names(r_times_laptop_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

scala_times_laptop_IC <- cbind(1:100,read.csv("./data/scala_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "Scala (IC)")
names(scala_times_laptop_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

scala_times_laptop_MD <- cbind(1:100,read.csv("./data/scala_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "Scala (MD)")
names(scala_times_laptop_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
#+end_src

#+RESULTS:

We can now use ~ggplot~ to make a nice plot of this data.

Putting the data together and plotting

#+begin_src R :session example :results graphics file :file ./Figures/plot_complexity_laptop_1.png :width 1000 :exports both
data <- rbind(jax_times_laptop_32_IC, jax_times_laptop_32_MD,
              jax_times_laptop_64_IC, jax_times_laptop_64_MD,
              r_times_laptop_IC, r_times_laptop_MD,
              scala_times_laptop_IC, scala_times_laptop_MD)

#data <- rbind(r_times_laptop_IC, jax_times_laptop_32_MD)

time_graph <- ggplot(data, aes(x = d, y = time, color = proc)) +
  geom_line(size = 2) +
  scale_color_manual(values = c("JAX32 (IC)" = "darkred", "JAX32 (MD)" = "#FF7377",
                                "JAX64 (IC)" = "#D55E00", "JAX64 (MD)" = "#E69F00",
                                "Scala (IC)" = "darkblue", "Scala (MD)" = "#56B4E9",
                                "R (IC)" = "darkgreen", "R (MD)" = "#009E73")) +
  theme_minimal() + 
  labs(title = "Compute Time against Dimension (AMD Ryzen 7, 5700X, 16Gb RAM, Arch Linux)",
       x = "Dimension",
       y = "Compute Time (seconds)") +
  theme(text = element_text(size = 20))
print(time_graph)
#+end_src

#+RESULTS:
[[file:./Figures/plot_complexity_laptop_1.png]]

#+begin_src R :session example :results graphics file :file ./Figures/plot_complexity_laptop_1.png :width 1000 :exports both
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)


r_times_laptop_IC <- cbind(1:100,read.csv("./data/R_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "R")
names(r_times_laptop_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

scala_times_laptop_native <- cbind(1:100,read.csv("./data/scala_compute_times_laptop_1_nativeBlas.csv", header = FALSE)) %>%
  mutate(proc = "Scala (Native)")
names(scala_times_laptop_native) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
scala_times_laptop_java <- cbind(1:100,read.csv("./data/scala_compute_times_laptop_1_javaBlas.csv", header = FALSE)) %>%
  mutate(proc = "Scala (Java)")
names(scala_times_laptop_java) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
scala_times_laptop_open <- cbind(1:100,read.csv("./data/scala_compute_times_laptop_1_openBlas.csv", header = FALSE)) %>%
  mutate(proc = "Scala (Open)")
names(scala_times_laptop_open) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

data <- rbind(r_times_laptop_IC, scala_times_laptop_native, scala_times_laptop_java, scala_times_laptop_open)

time_graph <- ggplot(data, aes(x = d, y = time, color = proc)) +
  geom_line(size = 2) +
  scale_color_manual(values = c("JAX32 (IC)" = "darkred", "JAX32 (MD)" = "#FF7377",
                                "JAX64 (IC)" = "#D55E00", "JAX64 (MD)" = "#E69F00",
                                "Scala (IC)" = "darkblue", "Scala (MD)" = "#56B4E9",
                                "R (IC)" = "darkgreen", "R (MD)" = "#009E73")) +
  theme_minimal() + 
  labs(title = "Compute Time against Dimension (Intel core i7 12700H, 16Gb RAM, Arch Linux)",
       x = "Dimension",
       y = "Compute Time (seconds)") +
  theme(text = element_text(size = 20))
print(time_graph)
#+end_src
