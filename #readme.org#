#+TITLE: Adaptive Metropolis in Scala and JAX

:BOILERPLATE:
#+BIBLIOGRAPHY: Bibliography.bib
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [letterpaper]
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage{amsmath,amsfonts,amsthm,amssymb,bm,tikz,tkz-graph}
#+LATEX_HEADER: \usetikzlibrary{arrows}
#+LATEX_HEADER: \usetikzlibrary{bayesnet}
#+LATEX_HEADER: \usetikzlibrary{matrix}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \newtheorem{theorem}{Theorem}[section]
#+LATEX_HEADER: \newtheorem{corollary}[theorem]{Corollary}
#+LATEX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
#+LATEX_HEADER: \newtheorem{definition}[theorem]{Definition}
#+LATEX_HEADER: \newtheorem*{remark}{Remark}
#+LATEX_HEADER: \DeclareMathOperator{\E}{\mathbb E}}
#+LATEX_HEADER: \DeclareMathOperator{\var}{\mathbb V\mathrm{ar}}
#+LATEX_HEADER: \DeclareMathOperator{\cov}{\mathbb C\mathrm{ov}}
#+LATEX_HEADER: \DeclareMathOperator{\cor}{\mathbb C\mathrm{or}}
#+LATEX_HEADER: \newcommand*{\mat}[1]{\bm{#1}}
#+LATEX_HEADER: \renewcommand*{\vec}[1]{\boldsymbol{\mathbf{#1}}}
#+EXPORT_EXCLUDE_TAGS: noexport
:END:

This is my attempt at implementing Adaptive Metropolis in Scala, using the breeze library, and python, using JAX.

This is based on the example from the article "Examples of Adaptive MCMC" by Roberts and Rosenthal.

* Adaptive Metropolis Algorithm

A AMRTH step is defined as follows;
- If $j\leq 2d$, we do a MRTH step with proposal $q(x,\cdot)\sim \mathcal N(x,(0.1)^2I_d/d)$
- If $j>2d$, we use the proposal $q(\vec X_t^* \mid \vec X_0, \dots, X_{t-1}) \sim \mathcal N_d (\vec X_{t-1}, \mat C_j)$, where $C_j$ is the current sampling covariance, updated as below.
  
We can compute the empirical covariance matrix at step $j$ by
\begin{align*}
\vec{\overline{X}}_t &= \frac{t-1}{t} \vec{\overline{X}}_{t-1} + \frac{1}{t} \vec X_t, \\
\mat C_{t+1} &= \frac{t-1}{t} \mat C_t + \frac{s_d}{t}(t\vec{\overline{X}}_{t-1}\vec{\overline{X}}_{t-1}^{\intercal} - (t+1)\vec{\overline{X}}_t\vec{\overline{X}}_t^{\intercal} + \vec X_t\vec X_t^{\intercal} + \epsilon \mat I_d),\quad t\geq t_0.
\end{align*}
The logic I'm using is to carry forward $\vec{\overline x}$ and $C_j$ (as well as the current index, $j$) as part of our 'chain', in order to sample from the proposal.

** Measure of effectiveness

Roberts and Rosenthal also give the following measure of effectiveness;

$$\begin{aligned}
b = d\frac{\sum \lambda_i^{-2}}{(\sum \lambda_i^{-1})^2 }
\end{aligned}$$

where $\lambda_i$ are the eigenvalues of $\Sigma_p^{1/2}\Sigma^{-1/2}$ where $\Sigma_p$ is the empirical variance matrix at the pth iteration.

$b$ should approach 1 as the chain approaches the stationary distribution. Roughly, it measures the difference between the empirical and true variance matrices.

* Example Target

We target the distribution $\pi(\cdot)\sim \mathcal N(0,\Sigma)$, where $\Sigma$ is a matrix sampled from a 'standard' inverse Wishart distribution, i.e., $\Sigma=MM^{\intercal}$, where $M\in\mathbb R^{n \times n}$ is a matrix with random $\mathcal N[0,1]$ entries. In Scala, this can be found as below;

#+begin_src scala
import AdaptiveMetropolis._

// dimension of the state space
val d = 10

// create a chaotic variance to target
val data = Gaussian(0,1).sample(d*d).toArray.grouped(d).toArray
val M = DenseMatrix(data: _*)
val sigma = M.t * M
#+end_src

Note that Breeze's ~DenseMatrix~ and ~DenseVector~ are actually mutable in Scala, so we need to be careful not to mutate anything.

* Scala implementation

My Scala implementation of this is found in ~Main.scala~ (it needs cleanup though). It is built around an object ~Adaptive Metropolis~, with three methods:

- ~AM_step~, which takes the current state as well as the QR decomposition of the true variance, and outputs the next state of the chain.
- ~AM_iterator~, which iterates ~AM_step~ in order to create an infinite lazy list of samples.
- ~plotter~, which plots the 1st componant of the sample, and saves it to a file.
  
The ~run~ function then tests this, using ~d=10~, ~n=100000~, ~burnin=100000~ and ~thinrate=10~. This function, once it finishes, prints out the true variance of $x_1$, the empirical estimate of it from the sample, the $b$ value, and the time the computation took. A trace plot of $x_1$ is also saved to ~Figures/adaptive_trace_scala.png~.

*** TODO Properly Document and Comment the Scala code :projects:

* JAX implementation

As you might imagine, the JAX implentation is very similar, even if it is a bit more fragmented. The ~AM_step~ function is split into twofunctions, ~try_accept~, and ~adapt_step~. This is mainly due to the way JAX handles ~if else~ statements, making this seem like the convenient way to do it.

In the file ~AM_in_JAX.org~, there is the source code as well as documentation for all the functions, but it is very similar to the scala version.

* Results

In all implementations, we run with ~d=100~, ~n=100, ~burnin=0~ and ~thinrate=10000~. These settings roughly match the original C code from Roberts and Rosenthal, where 100 iteration results where saved.

For context, the original C code by Roberts and Rosenthal with d=100, n=1000000, took 431.122329 seconds.

The full results of these tests can be made using the ~run.sh~
script found at the root of the project. It also saves the trace plots as ~/Figures/<language>_trace_basetest.png~.

In R:

#+begin_quote
The optimal sampling value of x_1 is 0.02486704566808
The actual sampling value of x_1 is 0.0209341928404325
The initial b value is 1.83282541152906
The final b value is 1.02525674146274
The acceptance rate is 0.103388
The computation took 202.283761262894 seconds

#+end_quote

#+ATTR_ORG: :height 100
[[file:./Figures/r_trace_basetest.png]]

In Scala:

#+begin_quote
The optimal sampling variance of x_1 is 0.02486704566808
The actual sampling variance of x_1 is  0.01937688808349585
The initial b value is 73.4639993467733
The final b value is 1.2516212501470279
The acceptance rate is 0.104118
The computation took 435.751518877 seconds
#+end_quote

#+ATTR_ORG: :height 100
[[file:./Figures/scala_trace_basetest.png]]

And finally in JAX,

#+begin_quote
The optimal sampling variance of x_1 is 0.024867046624422073
The actual sampling variance of x_1 is  0.019067611545324326
The initial b value is 73.5059814453125
The final b value is 1.2530319690704346
The acceptance rate is 0.10468100011348724
The computation took 90.90827989578247 seconds
#+end_quote

#+ATTR_ORG: :height 100
[[file:./Figures/jax_trace_basetest.png]]

or in JAX with mixing

#+begin_quote
JAX output (mixing): 
The optimal sampling variance of x_1 is 0.024867046624422073
The actual sampling variance of x_1 is  0.018218811601400375
The initial b value is 73.5059814453125
The final b value is 1.0261740684509277
The acceptance rate is 0.31248700618743896
The computation took 48.6323938369751 seconds
#+end_quote

* Complexity vs time

In order to get a better idea of how these implementations compare, we use the same chaotic variance matrix for both, with increasing submatrices, so we can make a graph of problem dimension, ~d~, against time.

Firstly, here is a little python code to write out the matrix to a csv file, so both programs can read it, so we control the target variance;

#+begin_src python :session example :results file
import jax
import jax.numpy as jnp
import jax.random as rand
import csv
import numpy as np
from jax.numpy.linalg import solve, qr, norm, eig, eigh, inv, cholesky, det

# keys for PRNG
key = rand.PRNGKey(seed=1)

d = 100

# create a chaotic variance matrix to target
M = rand.normal(key, shape = (d,d))
sigma = inv(M @ M.T)

with open('data/very_chaotic_variance.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerows(np.array(sigma))



    
'data/chaotic_variance.csv'
#+end_src

#+RESULTS:
[[file:data/chaotic_variance.csv]]

From here, both versions have a function ~compute_time_graph~ which outputs a csv file containing the time it took to compute over a million iterations for each submatrix of the intputted variance matrix, whcih will be provided from this file. This is then plotted as below using R.

#+begin_src R :session example :results none
#library(ascii)
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)
#+end_src

#+begin_src R :session example :results output
jax_times_laptop_32_IC <- cbind(1:100,read.csv("./data/JAX_32_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "JAX32 (IC)")
names(jax_times_laptop_32_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
jax_times_laptop_32_MD <- cbind(1:100,read.csv("./data/JAX_32_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "JAX32 (MD)")
names(jax_times_laptop_32_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

jax_times_laptop_64_IC <- cbind(1:100,read.csv("./data/JAX_64_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "JAX64 (IC)")
names(jax_times_laptop_64_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
jax_times_laptop_64_MD <- cbind(1:100,read.csv("./data/JAX_64_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "JAX64 (MD)")
names(jax_times_laptop_64_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

r_times_laptop_IC <- cbind(1:100,read.csv("./data/R_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "R (IC)")
names(r_times_laptop_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
r_times_laptop_MD <- cbind(1:100,read.csv("./data/R_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "R (MD)")
names(r_times_laptop_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")

scala_times_laptop_IC <- cbind(1:100,read.csv("./data/scala_compute_times_laptop_1_IC.csv", header = FALSE)) %>%
  mutate(proc = "Scala (IC)")
names(scala_times_laptop_IC) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
scala_times_laptop_MD <- cbind(1:100,read.csv("./data/scala_compute_times_laptop_1_MD.csv", header = FALSE)) %>%
  mutate(proc = "Scala (MD)")
names(scala_times_laptop_MD) <- c("d","n", "thinrate", "burnin", "time", "b", "proc")
#+end_src

#+RESULTS:

We can now use ~ggplot~ to make a nice plot of this data.

Putting the data together and plotting

#+begin_src R :session example :results graphics file :file Figures/plot_complexity_laptop_1.png :width 1000 :exports both
#data <- rbind(jax_times_laptop_32_IC, jax_times_laptop_32_MD,
#              jax_times_laptop_64_IC, jax_times_laptop_64_MD,
#              r_times_laptop_IC, r_times_laptop_MD,
#              scala_times_laptop_IC, scala_times_laptop_MD)

data <- rbind(r_times_laptop_IC, jax_times_laptop_32_MD)

time_graph <- ggplot(data, aes(x = d, y = time, color = proc)) +
  geom_line(size = 2) +
  scale_color_manual(values = c("JAX32 (IC)" = "red", "JAX32 (MD)" = "pink",
                                "JAX64 (IC)" = "#E69F00", "JAX64 (MD)" = "#D55E00",
                                "Scala (IC)" = "blue", "Scala (MD)" = "#56B4E9",
                                "R (IC)" = "darkgreen", "R (MD)" = "#009E73")) +
  theme_minimal() + 
  labs(title = "Compute Time against Dimension (Intel core i7 12700H, 16Gb RAM, Arch Linux)",
       x = "Dimension",
       y = "Compute Time (seconds)") +
  theme(text = element_text(size = 20))
print(time_graph)
#+end_src

#+RESULTS:
[[file:Figures/plot_complexity_laptop_1.png]]

(for Scala (IC), I am reasonably sure i unplugged my laptop for the last chunk, explaining the odd results)

(I can also confirm that settings were incorrect pretty much across the board!)

We can also plot the final sub-optimality factor, $b$, over all the dimensions;

#+begin_src R :session example :results graphics file :file Figures/plot_b_laptop.png :width 1000 :exports both
b_graph <- ggplot(data, aes(x = d, y = b, color = proc)) +
  geom_line(size = 2) +
  scale_color_manual(values = c("JAX32 (IC)" = "red", "JAX32 (MD)" = "pink",
                                "JAX64 (IC)" = "#E69F00", "JAX64 (MD)" = "#D55E00",
                                "Scala (IC)" = "blue", "Scala (MD)" = "#56B4E9",
                                "R (IC)" = "darkgreen", "R (MD)" = "#009E73")) +
  theme_minimal() + 
  labs(title = "Effectiveness against Dimension (Intel core i7 12700H, 16Gb RAM, Arch Linux)",
       x = "Dimension",
       y = "b") +
  theme(text = element_text(size = 20))
print(b_graph)
#+end_src

#+RESULTS:
[[file:Figures/plot_b_laptop.png]]

In truth, both of the above are in IC mode. Where does the difference come from?

I believe this confirms that the r result should be ignored, there is something different with that version.

We can see that while both perform equally as well, JAX maintains a good lead in terms of speed over both Scala and especially R.

* Mixing

This is the graph comparing the two versions of the algorithms' mixing capabilities (full description to be written)

#+begin_src R :session example :results graphics file :file ./Figures/plot_mixing.png :height 600 :width 1200 :exports both
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)

jax_b_mixing <- cbind(1:100,read.csv("./data/so_factor_mixing.csv", header = FALSE)) %>%
  mutate(proc = "Mixing")
names(jax_b_mixing) <- c("NA", "j","b", "proc")
jax_b_not_mixing <- cbind(1:100,read.csv("./data/so_factor_no_mixing.csv", header = FALSE)) %>%
  mutate(proc = "Not Mixing")
names(jax_b_not_mixing) <- c("NA", "j","b", "proc")

data <- rbind(jax_b_mixing, jax_b_not_mixing)

plot_mixing <- ggplot(data, aes(x = j, y = b, color = proc)) +
  geom_line(size = 2) +
  scale_color_manual(values = c("Mixing" = "blue", "Not Mixing" = "red")) +
  theme_minimal() + 
  labs(title = "Mixing Factor (Intel core i7 12700H, 16Gb RAM, Arch Linux)",
       x = "j",
       y = "b") +
  theme(text = element_text(size = 20))
print(plot_mixing)
#+end_src

#+RESULTS:
[[file:./Figures/plot_mixing.png]]
